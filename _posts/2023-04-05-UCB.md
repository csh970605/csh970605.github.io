---
title: Upper Confidence Bound(UCB)
author: SeHoon
date: 2023-04-06 14:41:30 +0900
categories: [Machine Learning, ML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is UCB?

UCB finds a way to combine "exploration" with "exploitation" to get the best result.
<br><br>

## Algorithm of UCB
---
<br>

Let's assume that we are planning an advertisement.<br>
There are 3 steps to get the result:

+ Step 1. <br>
at each round n, we consider two numbers for each ad *i*:
    + N_{i}(n) : The number of times the ad *i* was selected up to round *n*.<br>
    + R_{i}(n) : The sume of rewards of the ad *i* up to round *n*.<br>

+ Step 2.<br>
From these two numbers we compute:
    + the average reward of ad *i* up to round *n*.<br>
    <center>
    <font size=4>

    $\bar{r_{i}} = \frac{R_{i}(n)}{N_{i}(n)}$
    
    </font>
    </center>

    + the confidence interval $\bar{r_{i}}\ -\ \Delta_{i}(n),\ \bar{r_{i}}\ +\ \Delta_{i}(n) $ at round *n* with<br>

    <center>
    <font size=4>

    $\Delta_{i}(n)\ =\ \sqrt{\frac{3log(n)}{2N_{i}(n)}}$
    
    </font>
    </center>

+ Step 3. we select the ad *i* that has the maximum UCB( $ \bar{r_{i}}\ +\ \Delta_{i}(n) $).

<br><br>

## The process of deriving the result value of UCB
---
<br>

Let's assume we have an initial distribution for ads.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230291095-6be24208-5539-49f7-a1df-263986e3b527.png" width=500>
</center>
<br><br>
And I'm going to take this value and put it on the vertical axis.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230290469-d5cb319a-14f4-4d5b-baf1-0127dd4dd00a.png" width=500>
</center>
<br><br>
Assume starting points from the distributions D1, D2, D3, D4, and D5. <br>
And I'll put it at the same level, assuming that all the same profits come back.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230291292-72ce1b7d-4952-461b-b8e3-cd4dc830cff3.png" width=500>
</center>
<br><br>
Then, they create a confidence bands. They are built with a very high level of certainty and contain actual returns or actual expected returns.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230292081-789a5c5e-f79b-47a2-adf7-16e61535787d.png" width=500>
</center>
<br><br>
After that, the alogirthm will choose one box randomly.<br>
Returns whether it is true or false depending on the observed value.<br>
In our case, we chose D3 and returned false.<br>
If so, the red dotted line goes down, and the confidence interval (box) shrinks because we have additional observation, we are more confident in our predictions.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230293106-93ff87a6-cb53-42bc-a28a-ba0bbf6a2fc6.png" width=500>
</center>
<br><br>
The next step, we find the next one with the highest confidence bound.<br>
Choose randomly if there is more than one of the highest confidence bounds.<br>
Then, repeat above.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230293940-bb9b555e-2cb4-4c82-b617-a980485974d5.png" width=500>
</center>
<br><br>
If we repeat what we have done so far, the best value is found.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/230294175-093bbb02-020b-4c46-a73a-3039fcb0c786.png" width=500>
</center>
<br><br>

# Example
<br><br>

## Code
---
<br>

```py
import math

N = 10000
d = 10
ads_selected = []
numbers_of_selections = [0] * d
sums_of_rewards = [0] * d
total_reward = 0
for n in range(N):
  ad = 0
  max_upper_bound = 0
  for i in range(d):
    if numbers_of_selections[i] > 0:
      average_reward = sums_of_rewards[i] / numbers_of_selections[i]
      delta_i = math.sqrt((3/2) * (math.log(n+1)/numbers_of_selections[i]))
      upper_bound = average_reward + delta_i
    else:
      upper_bound = 1e400
    if upper_bound > max_upper_bound:
      max_upper_bound = upper_bound
      ad = i
  ads_selected.append(ad)
  numbers_of_selections[ad] += 1
  reward = dataset.values[n, ad]
  sums_of_rewards[ad] += reward
  total_reward += reward

plt.hist(ads_selected)
plt.title('Histogram of ads selections')
plt.xlabel('Ads')
plt.ylabel('Number of times each ad was selected')
plt.show()
```

<br><br>

## Result

<center>
<img src="https://user-images.githubusercontent.com/28240052/230294519-58d39468-1184-40ea-a9a4-cac4dd83d03d.png">
</center>
<br><br>