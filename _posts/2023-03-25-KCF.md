---
title: KCF
author: SeHoon
date: 2023-03-25 22:04:00 +0900
categories: [Vision Machine Learning, VML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# KCF(Kernelized Correlation Filters)<br>
Runs very fast, but the quality is not so good especially in fast videos.<br>
**Most common problem occurs when the bounding box loses the object.** <br>
The larger frames that were automatically generated are important to detect changes in the scale which represents the size of the objects.<br>
Example of size change: if in one frame the object is smaller and in the next frame the object increases size like a person approaching the camera.<br>
<br>

## Goal
---
The goal of the KCF is to make several adjustments in bounding boxes in order to circle the object and be able to detect it.<br>

<br>

## How KCF works?
---
+ Frame 1(Initialization)<br>
We have the first frame, which is the initialization or the definition of the object to be detected.<br>
Algorithm applies a particle filter(red box) and two more bounding boxes are created to cover a large parts of the image(blue box, green box)<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/227716410-6727de58-550e-4616-b235-2e9db27898ef.png"><br>
</center><br>

+ Frame 2 & Frame 3(Translation Estimation)<br>
The larger rectangle is used the green box(filter) and some mathematical calculations are made to adjust the fram in the central parts of face as written in image below.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/227716442-f513f880-8d20-4092-b94c-75c8bebe4649.png"><br>
</center><br>

+ Frame 4 & Frame 5(Translation Estimation)<br>
The blue box(filter) is updated to the central position of the face.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/227716473-a5ba13e6-38dc-4a85-aecb-89563ad79053.png"><br>
</center><br>

+ Frame 6(Scale Estimation)<br>
The red box(filter) is updated to the central position of the face.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/227716479-f1ef642d-e891-4fda-abbf-6739c475c39e.png"><br>
</center><br>

+ Frame 7(Translation Estimation)<br>
Before this step, the first update of all filters is done.<br>
From now on, we repeat what we did from frame2 to frame6 with the box slightly smaller.<br>
This means, it was adjusted to the object.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/227716486-98efa8f5-cc24-486d-a772-76345cc8d638.png"><br>
</center><br>
<br>
<br>

# Exmaple Code<br>
```py
tracker = cv2.TrackerKCF_create()
video = cv2.VideoCapture('race.mp4')
# ok: discriminate open cv correctly reads.
# frame : will start the first frame of the video.
ok, frame = video.read()

bbox = cv2.selectROI(frame)

ok = tracker.init(frame, bbox)

#Accesing frame by frame
while True:
    ok, frame = video.read()
    
    if not ok:
        break
    ok, bbox = tracker.update(frame)
    
    if ok:
        (x, y, w, h) = [int(v) for v in bbox]
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2, 1)
    else:
        cv2.putText(frame, 'Error', (100, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    
    cv2.imshow('Tracking', frame)
    if cv2.waitKey(1) & 0XFF ==27: # 0XFF:ESC
        break
```

<br><br><br>

## Result<br>
---
<br>
A window named ROI selector will appear after existing code above.<br>
At the window, select object which you want to track by mouse like image below.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/227764927-4f68a123-3778-473d-844e-f2b16a6c8418.png">
</center>
<br><br>
After selecting the object to be tracked, a screen like the one below will appear.<br>
<img src="https://drive.google.com/uc?export=view&id=1AItksNb4tOyyFbFXamHglcgwCqesazmg"><br>