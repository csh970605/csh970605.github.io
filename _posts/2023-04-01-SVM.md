---
title: Support Vector Machine(SVM)
author: SeHoon
date: 2023-04-01 15:35:30 +0900
categories: [Machine Learning, ML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is SVM?

Like [Support Vector for Regression (SVR)](https://csh970605.github.io/posts/SVR/), there is a straight line called the Maximum Margin between two categories. The **Maximum Margin Hyperplane** is drawn equidistant from the two nearest points in each category. The two nearest points are called **Support Vectors**.<br>
As you can see in the image below, a straight line parallel to the Maximum Margin Hyperplane and passing through the support vectors becomes a **hyperplane**. The hyperplane supports the decision boundary which is called Maximum Margin.<br>

<center>
<img src="https://user-images.githubusercontent.com/28240052/229291494-9e75de85-a3c7-464c-ac92-eca3d10f83d8.png">
</center>
<br>
Thus, new data is classified according to whether it is in the negative or positive hyperplane.<br>

# Example
<br><br>

## Code
---
<br>

```py
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

classifier = SVC(kernel='linear') # you can change kernel if you want other model
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
```

<br><br>

## Result
---
<br>

<center>
<img src="https://user-images.githubusercontent.com/28240052/229292381-6b27ffcd-1d5d-48eb-944c-dd178cc47aca.png" width=500>
</center>

<br><br><br><br>

# Implementation

+ [SVM](https://github.com/csh970605/Machine-LearningA-Z/tree/main/Part%203%20-%20Classification/Section%2016%20-%20Support%20Vector%20Machine%20(SVM)/Python)