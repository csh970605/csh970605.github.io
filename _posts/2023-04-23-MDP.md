---
title: Markov Decision Process(MDP)
author: SeHoon
date: 2023-04-23 16:50:30 +0900
categories: [Deep Reinforcement Learning, DRL_Theory]
tags: [deep reinforcement learning, python]
math: true
mermaid: true
---

# What is MDP?

Since few things are 100% certain in the real world, a more advanced formula than [Bellman equation](https://csh970605.github.io/posts/Bellman_Equation/) is needed.<br>
For this reason, MDP is devised.<br><br>
Assume that there is A case where you need to choose a direction.
<center>
<img src="https://user-images.githubusercontent.com/28240052/233836150-893cd814-f899-4b54-bc0c-b6dca90207cb.png" width=400>
</center>
<br><br>
According to the bellman equation, the robot moves up 100%. This is because in the bellman equation there is no probability of going left or right.
<center>
<img src="https://user-images.githubusercontent.com/28240052/233836258-1a1a1da9-b4fc-472c-9e11-a8dd3063b3cd.png" width=300>
</center>
<br><br>
But in MDP, the robot moves in various directions because there is a probability to go right or left.
<center>
<img src="https://user-images.githubusercontent.com/28240052/233836330-70ad254b-671c-4119-9f2d-75fbc2787c27.png" width=600>
</center>
<br><br><br>

# The formula of MDP

<center>
<font size=4>

$ V(s)\ =\ max(R(s,a)\ +\ \gamma \Sigma_{s'}P(s,a,s')V(s')) $
</font>
</center>

<center>
<img src="" width=500>
</center>
<br><br>