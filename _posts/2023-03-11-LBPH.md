---
title: LBPH
author: SeHoon
date: 2023-03-11 22:28:00 +0900
categories: [Vision Machine Learning, VML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is LBPH?
LBP (Local Binary Patterns) is a feature extraction technique used to recognize or analyze textures in the field of image processing. <br>
LBPH is a technique that combines LBP and a histogram (H).<br><br>
LBP extracts features of an image by converting the pixel values around each pixel in the image into binary numbers like image below.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/224699726-5ff044c2-a8e6-4ccc-93f2-06338b3574c7.png"><br>
</center>
Binary numbers are generated based on the relative brightness difference between the center pixel and its neighbors.<br>
If the neighboring pixel's value is larger than the center pixel's value, it is represented as 1, and if it is less than the center pixel'value, it is represented as 0 like image below.<br>
<center>
<img src="https://user-images.githubusercontent.com/28240052/224700196-71f56fd3-a67a-4457-b943-f16b545b1f6e.png">
</center>
<br>
Using these binary numbers, we can extract texture features for each pixel.<br>
The image below shows the order of extracting binary numbers.
<center>
<img src="https://user-images.githubusercontent.com/28240052/224703312-78acf600-d5c5-41ed-a588-233f3a195c54.png">
</center>
The result of the value extracted from the image is "11100010" in binary and "226" in decimal. That is, the value of the pixel surrounding 8 in the image is "11100010" in binary and "226" in decimal.<br>
Also, this value does not change even if the brightness of the image is increased.<br>
<br>
Extracting Local Binary Patterns (LBP) can result in specific patterns appearing in specific parts of an image. <br>
It uses these patterns to recognize objects or faces in images.<br>
<br>

# How is LBPH applied to actual images?


## Step 1
---
<br>
<img src="https://user-images.githubusercontent.com/28240052/225900490-974f53c4-20b8-46b1-a6ff-156424ca9856.png"><br><br>
As you can see in the picture above, algorithm will create several squares.<br>
It should be noted here that a square does not represent a single pixel, but are set with multiple pixels.<br>
In this picture, each square has 12pixels. And then, apply LBP to obtain the value of the central pixel.<br><br>

## Step 2
---
<br>

Create a histogram, which represent statistics of counts that how many times each color appears in each squares.<br>
The image below is an example of a created histogram.<br>
<br>
<img src="https://user-images.githubusercontent.com/28240052/225904718-8fc18f23-5bc3-4d49-a435-aa84d5a9da0f.png">
<br><br>

## Step 3
---
<br>
Based on the comparision of the histograms, the algorithm identifies which part each square represents.<br><br>

# Example Code
<br>
There are two ways to recognize faces.<br>
The first way is using openCV. And the second way is using dlib.

## Implement by openCV
---
<br>

### Training LBPH Classifier
---
<br>

```py
# faces and ids: image and id values composed of numpy arrays extracted from a specific image.
lbph_classifier = cv2.face.LBPHFaceRecognizer_create(radius=4, neighbors=14, grid_x=9, grid_y=9)
lbph_classifier.train(faces, ids)
lbph_classifier.write('lbph_classifier.yml')
```
<br>

the result that written in 'lbph_classifier.yml' : 

```py
# threshold: 1.7976931348623157e+308
# radius: 1
# neighbors: 8
# grid_x: 8
# grid_y: 8
```

#### Parameters of LBPH
---
<br>
There are 4 parameters.<br>

+ radius : being used to build the circular local binary pattern and represents the radius around the central pixel. <br>
+ neighbors : the number of sample points to build the circular local binary pattern. **the more sample points you include, the higher the computational cost.**<br>
+ grid_x : the number of cells in the horizontal direction. The more cells, the finer the grid, the higher the dimensionality of the resulting feature vector. 
+ grid_y : the number of cells in the vertical direction. The more cells, the finer the grid, the higher the dimensionality of the resulting feature vector.

<br><br>

### Recognizing faces
---
<br>

```py
lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_face_classifier.read('lbph_classifier.yml')
test_image = 'yalefaces/test/subject10.sad.gif'

image = Image.open(test_image).convert('L') # 'L' means convert .gif to image
image_np = np.array(image, 'uint8')

prediction = lbph_face_classifier.predict(image_np)
# prediction[0]: class
# prediction[1]: confidence(the higher value, the higher prediction)

cv2.putText(image_np, 'Pred: '+str(prediction[0]), (10, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 0))
cv2.putText(image_np, 'EXP: '+str(expected_output), (10, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 255, 0))

cv2_imshow(image_np)
```
<br>

The result of codes above :
<br>
<img src="https://user-images.githubusercontent.com/28240052/226274801-e1e05f6b-0662-42d1-8068-88db55999763.png">
<br><br>

## Implement by Dlib


<img src="https://user-images.githubusercontent.com/28240052/226342348-b971799c-39af-4b3a-b60a-b72c4542c2d2.png">
<br>
As you can see in the image above, there are some common features in my implementation, such as five dots in the eyebrows and four dots on the nose bridge.
