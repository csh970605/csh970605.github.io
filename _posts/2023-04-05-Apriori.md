---
title: Apriori
author: SeHoon
date: 2023-04-05 22:32:30 +0900
categories: [Machine Learning, ML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is Apriori?
Apriori is an algorithm for frequent itemset mining and association rule learning. It proceeds by identifying the frequent individual items in the dataset and extending them to larger and larger itemsets as long as those itemsets appear frequently enough in the dataset.<br>
The Apriori algorithm has three parts:<br>

+ Support<br>
It is very similar to [Bayes](https://csh970605.github.io/posts/Naive_Bayes/).<br>
Let's assume that we are doing a movie recommendation.<br>

<center>

$ support(M) = \frac{\text{user watching lists containing } M}{\text{user watchlists}} $
</center>

+ Confidence<br>
Confidence is defined as the number of people who have seen both M1 and M2 movies divided by the number of people who have seen M1.<br>
<center>

$ confidence(M_{1} \rightarrow M_{2}) = \frac{\text{user watching lists containing } M_{1} \text{ and } M_{2}}{\text{user watchlists containing } M_{1}} $
</center>


+ Lift<br>
<center>

$lift(M_{1} \rightarrow M_{2}) = \frac{confidence(M_{1} \rightarrow M_{2})}{support(M_{2})}$
</center>
<br><br>

## The order of progression of apriori
---
<br>

+ Step 1.<br>
Set minimum support and confidence thresholds.<br>
+ Step 2.<br>
Take all subsets in transactions with support higher than the minimum support threshold.<br>
+ Step 3.<br>
Take all the rules of these subsets with confidence higher than the minimum confidence threshold.<br>
+ Step 4.<br>
Sort the rules by decreasing lift values.<br>
<br><br><br>

# Example
<br><br>

## Code
---
<br>

```py
from apyori import apriori
rules = apriori(
                transactions=transactions, 
                min_support=0.003, 
                min_confidence=0.2, 
                min_lift=3, 
                min_length=2, 
                max_length=2)

results = list(rules)


def inspect(results):
  lhs = [tuple(result[2][0][0])[0] for result in results]
  rhs = [tuple(result[2][0][1])[0] for result in results]
  supports = [result[1] for result in results]
  confidences = [result[2][0][2] for result in results]
  lifts = [result[2][0][3] for result in results]
  return list(zip(lhs, rhs, supports, confidences, lifts))


resultsinDataFrame = pd.DataFrame(inspect(results), columns = [
                                                                'Left Hand Side', 
                                                                'Right Hand Side', 
                                                                'Support', 
                                                                'Confidence', 
                                                                'Lift'])

resultsinDataFrame = resultsinDataFrame.nlargest(n=10, columns='Lift')                                                                
```

## Result
---
<br>

<center>
<img src="https://user-images.githubusercontent.com/28240052/230103651-2e0fcac7-12b4-46c8-9073-c6300ff92512.png" width=500>
</center>

<br><br><br><br>

# Implementation

+ [Apriori](https://github.com/csh970605/Machine-LearningA-Z/tree/main/Part%205%20-%20Association%20Rule%20Learning/Section%2028%20-%20Apriori/Python)