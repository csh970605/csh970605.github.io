---
title: CSP(Cross Stage Partial Connections)
author: SeHoon
date: 2023-06-10 21:50:00 +0900
categories: [Vision Machine Learning, VML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is CSP?
CSP is a concept to reduce the amount of computation while making many gradient combinations. As the solution, input to a dense block of CSP is divided into two parts.
<br>
One is used directly into the concatenation with the final output of the DB+TB chain and the other is used as an input in the dense block like:
<br>

<center>
<img src="https://github.com/csh970605/csh970605.github.io/assets/28240052/f55bb97a-e1bd-4e7a-915e-2b1803b6d6f4" width=800>
</center>
<br><br>

By this concept, we can get two advantages.

+ Increasing the gradient flow paths that help in removing the replicated updates of the weights in dense block.

+ Breaking a base layer into two parts helps to decrease the number of multiplications in dense  block, which further helps in increasing inference speed.

<br><br><br><br>

# DenseBlock

DenseBlock is designed to perform [pooling](https://csh970605.github.io/posts/Pooling/) on [CNNs](https://csh970605.github.io/posts/CNN/) on DenseNet.<br>
<center>
<img src="https://github.com/csh970605/csh970605.github.io/assets/28240052/1c82f509-a711-4feb-a792-eebb6c2e03d5" width=700>
</center>
<br><br>



## DenseNet
---
<br>

Concatenate feature maps from all layers. Links the feature maps of the previous layer to the feature maps of all layers after it. Thus, size of every feature maps must be same and the number of feature maps must be greatly small.

<center>
<img src="https://github.com/csh970605/csh970605.github.io/assets/28240052/d6c5f111-dda5-40f4-9633-cf74d3f65069" width=800>
</center>
<br><br>

Perform pooling operation between dense blocks. The pooling operation is performed with BN, 1x1conv, and 2x2 avg_pool. And we call this the transition layer.<br>
If the number of input channels of the transition layer is $m$, $\theta \times m$ number of channels is output. That is, transition layer decreases the size of feature map(growth rate) and the number of channels.


<br><br><br><br>

# CSP Darknet

<center>
<img src="https://github.com/csh970605/csh970605.github.io/assets/28240052/c6a7c289-eb62-4dea-803e-28ace55dd5b9" width=300>
</center>
<br><br>