---
title: Twin Delayed DDPG(TD3)
author: SeHoon
date: 2023-04-27 22:33:30 +0900
categories: [Deep Reinforcement Learning, DRL_Introduction]
tags: [deep reinforcement learning, python]
math: true
mermaid: true
---

# What is Twin Delayd DDPG(TD3)?

TD3 is one of the deep [reinforcement learning](https://csh970605.github.io/posts/Reinforcement_Learning/).<br>
TD3 double learns with one optimal value, and the doulbe learning includes two [actor models](https://csh970605.github.io/posts/Actor_Critic/) and four [critic models](https://csh970605.github.io/posts/Actor_Critic/). And also [policy gradient](https://csh970605.github.io/posts/Policy_Gradient/) is used to update actor model through the Q values optimized by critic model.
<br>
The basic shape of TD3 is:

<center>
<img src="https://user-images.githubusercontent.com/28240052/235915907-4c133354-3fd8-4141-b495-2bbada1bca32.png" width=800>
</center>
<br><br>
And the steps of weights updating are actor target &rarr; critic targets &rarr; critic models &rarr; actor model

<br>
<br>
<br>

# Stpes of implement TD3
<br>

+ Step 1<br>
Initialize the **Experience Replay Memory** that stores past trasitions from which we are going to learn our Q values.<br>
And the Experience Replay Memory is consisted of:<br>
```
   s  : current state
   s' : next state
   a  : action played, it leads s to s'
   r  : reward
```

<center>
<img src="https://user-images.githubusercontent.com/28240052/235912996-969b724e-324d-4bff-9f9a-52f51db1e92c.png" width=500>
</center>
<br><br>

+ Step 2<br>
Build one neural network fro the actor model and one neural network for actor target.
<center>
<img src="https://user-images.githubusercontent.com/28240052/235914517-9e24b309-33f5-4695-a345-32c2232e059c.png" width=700>
</center>
<br><br>

<center>
<img src="https://user-images.githubusercontent.com/28240052/235915104-7bea795e-258f-4fff-98c2-6fdcfeee9975.png" width=700>
</center>
<br><br>

+ Step 3<br>
Build two neural networks for the two Critic models and two neural networks for the two Critic targets.
<center>
<img src="https://user-images.githubusercontent.com/28240052/235916575-1a076a65-58b6-4043-9e62-af85c31d7db6.png" width=800>
</center>
<br><br>

<center>
<img src="" width=500>
</center>
<br><br>

+ Step 4<br>
Run a full episode with certain numbers of actions randomly to avoid to end up in a bad state. And then with actions played by the actor model

<br>
<br>
<br>

# Steps of training TD3
<br>

+ Step 1


















# Exmaple Code<br>

```py
```

<br><br><br>

## Result
---
<br>
<img src="https://drive.google.com/uc?export=view&id=1ODPTkc7q-Iap2969bwkJMjluPm5iDRCR"><br>