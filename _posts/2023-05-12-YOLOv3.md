---
title: YOLOv3(You Only Look Once)
author: SeHoon
date: 2023-05-12 22:47:00 +0900
categories: [Vision Machine Learning, VML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is [YOLO](https://csh970605.github.io/posts/YOLO/)v3?
YOLO is similar to [CNN](https://csh970605.github.io/posts/CNN/). However, there are no flattening layers in YOLOv3. The basic structure of YOLO is:
<center>
<img src="https://github.com/csh970605/Machine-LearningA-Z/assets/28240052/2710b848-27ec-453b-b417-048ccf2c697f" width=900>
</center>
<br><br>

As you can see in the image above, the goal of YOLO is to generate bounding boxes to detect the position of objects. In the process of YOLO, **concatenation** occurs, copying the image and joining it before applying preprocessing steps. This concatenation enhances the model's ability to detect objects. **Residual blocks** are convolutional layers. One advantage of YOLO is its ability to detect the same object at different sizes, including smaller objects.

<br><br><br><br>

# Implementation

+ [Object tracking with YOLO](https://github.com/csh970605/Computer-Vision-Masterclass/tree/main/Section%209) : I used darknet to implement it.<br>

+ [YOLOv3 in using cv2.dnn.readNetFrom()](https://github.com/csh970605/Modern_Computer_Vision/blob/main/OpenCV/33.%20YOLOv3%20in%20OpenCV.ipynb)