---
title: Deep Face
author: SeHoon
date: 2023-06-09 10:32:00 +0900
categories: [Vision Machine Learning, VML_Theory]
tags: [machine learning, python]
math: true
mermaid: true
---

# What is Deep Face?

Deep Face is API to do [face recognition](https://csh970605.github.io/posts/Face-Recognition/) and facial attribute analysis(age, gender, emotion, race).<br>
There are 5 methods in Deep Face.
<br><br><br><br>

## Methods of Deep Face
---
<br>

+ Facial Attribute Analysis : It does face recognition and facial attribute analysis(age, gender, emotion, race). It can be done by **DeepFace.analyze(img_path, actions=['emotion', 'age', 'gender', 'race'], enforce_detection=True, detector_backend='opencv', align=True, silent=False) -> obj** where:<br>

    + img_path : Exact image path as string, numpy array (BGR) or based64 encoded images are also welcome. If one of pair has more than one face, then we will compare the face pair with max similarity.

    + actions : You can drop some of those attributes.

    + enforce_detection : If no face could not be detected in an image, then this function will return exception by default. Set this to False not to have this exception. This might be convenient for low resolution images.


    + detector_backend : Set face detector backend

    + silent : Disable some logging and progress bars

    + obj : Returns a list of dictionaries for each face appearing in the image.
    ```
    [
        {
            "region": {'x': 230, 'y': 120, 'w': 36, 'h': 45},
            "age": 28.66,
            "dominant_gender": "Woman",
            "gender": {
                'Woman': 99.99407529830933,
                'Man': 0.005928758764639497,
            }
            "dominant_emotion": "neutral",
            "emotion": {
                'sad': 37.65260875225067,
                'angry': 0.15512987738475204,
                'surprise': 0.0022171278033056296,
                'fear': 1.2489334680140018,
                'happy': 4.609785228967667,
                'disgust': 9.698561953541684e-07,
                'neutral': 56.33133053779602
            }
            "dominant_race": "white",
            "race": {
                'indian': 0.5480832420289516,
                'asian': 0.7830780930817127,
                'latino hispanic': 2.0677512511610985,
                'black': 0.06337375962175429,
                'middle eastern': 3.088453598320484,
                'white': 93.44925880432129
            }
        }
    ]
    ```

<br><br>

    

+ Face Verification : This function verifies face pairs as same person or different persons. It can be performed by **DeepFace.verify(img1_path, img2_path, model_name='VGG-Face', detector_backend='opencv', distance_metric='cosine', enforce_detection=True, align=True, normalization='base') -> obj** where:<br>

    + img1_path : Exact image path as string, numpy array (BGR) or based64 encoded images are also welcome. If one of pair has more than one face, then we will compare the face pair with max similarity.

    + img2_path : Exact image path as string, numpy array (BGR) or based64 encoded images are also welcome. If one of pair has more than one face, then we will compare the face pair with max similarity.


    + model_name : Model name.

    + detector_backend : Set face detector backend

    + distance_metric : Ways of calculating distance.

    + enforce_detection : If no face could not be detected in an image, then this function will return exception by default. Set this to False not to have this exception. This might be convenient for low resolution images.

    + obj : Returns a dictionary.

        ```
        {
            "verified": True, 
            "distance": 0.2563,
            "max_threshold_to_verify": 0.40,
            "model": "VGG-Face",
            "similarity_metric": "cosine",
            'facial_areas': {
                        'img1': {'x': 345, 'y': 211, 'w': 769, 'h': 769},
                        'img2': {'x': 318, 'y': 534, 'w': 779, 'h': 779}
            }, 
            "time": 2
        }
        ```

<br><br>    

+ Face Recognition : It's going to look for the identity of input image in the database path and it will return list of pandas data frame as output. It can be done by **DeepFace.find(img_path, db_path, model_name='VGG-Face', distance_metric='cosine', enforce_detection=True, detector_backend='opencv', align=True, normalization='base', silent=False) -> obj** where:<br>

    + img_path : Exact image path, numpy array (BGR) or based64 encoded image. Source image can have many faces. Then, result will be the size of number of faces in the source image.

    + db_path : A database image, it can also have many faces. Then, all detected faces in db side will be considered in the decision.

    + model_name : Model name.

    + distance_metric : Ways of calculating distance.

    + enforce_detection : Throws exception if a face could not be detected. Set this to True if you don't want to get exception. This might be convenient for low resolution images.

    + detector_backend : Set face detector backend

    + silent : Disable some logging and progress bars

    + obj : Returns list of pandas data frame. Each item of the list corresponding to an identity in the img_path.
<br><br>

    

+ Embeddings : It represent facial images as embedding vectors. It can be done by **DeppFace.represent(img_path, model_name='VGG-Face', enforce_detection=True, detector_backend='opencv', align=True, normalization='base')**

    + img_path : Exact image path, numpy array (BGR) or based64 encoded image. Source image can have many faces. Then, result will be the size of number of faces in the source image.

    + model_name : Model name.

    + enforce_detection : Throws exception if a face could not be detected. Set this to True if you don't want to get exception. This might be convenient for low resolution images.

    + detector_backend : Set face detector backend
    


+ Face Detector : It detects face and cut the image except face. It can be done by **DeepFace.extract_faces(img_path, target_size=(224, 224), detector_backend='opencv', enforce_detection=True, align=True, grayscale=False) -> obj** where:<br>

    + img_path : Exact image path, numpy array (BGR) or base64 encoded image. Source image can have many face. Then, result will be the size of number of faces appearing in that source image.

    + target_size : Final shape of facial image. black pixels will be added to resize the image.

    + detector_backend : Face detection backends

    + enforce_detection : Function throws exception if face cannot be detected in the fed image. Set this to False if you do not want to get an exception and run the function anyway.

    + grayscale : extracting faces in rgb or gray scale

    + obj : List of dictionaries. Each dictionary will have facial image itself, extracted area from the original image and confidence score.
<br><br>
<br><br>

### Detector Backends
---
<br>

+ 'opencv'

+ 'retinaface'

+ 'mtcnn'

+ 'ssd'

+ 'dlib'

+ 'mediapipe'

<br><br><br><br>

### Model Names
---
<br>

+ 'VGG-Face'

+ 'Facenet'

+ 'Facenet512'

+ 'OpenFace'

+ 'DeepFace'

+ 'Dlib'

+ 'ArcFace'

+ 'SFace'

+ 'Ensemble'

<br><br><br><br>

# Implementation

+ [DeepFace - Age, Gender, Expression, Headpose and Recognition](https://github.com/csh970605/Modern_Computer_Vision/blob/main/Deep%20Learning%20CV/41.%20DeepFace%20-%20Age%2C%20Gender%2C%20Expression%2C%20Headpose%20and%20Recognition.ipynb)